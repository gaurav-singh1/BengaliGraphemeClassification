{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\npt_models = \"../input/pretrainedmodels/pretrained-models.pytorch-master/\"\nsys.path.insert(0, pt_models)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport torch\nimport albumentations\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport joblib\nfrom PIL import Image\nimport torch.nn as nn\nfrom torch.nn import functional as F\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_BATCH_SIZE=32\nTEST_BATCH_SIZE=16\nMODEL_MEAN=(0.4, 0.4, 0.4)\nMODEL_STD=(0.2,0.2,0.2)\nIMG_HEIGHT = 137\nIMG_WIDTH = 236\nDEVICE=\"cuda\"\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resnet34(nn.Module):\n    def __init__(self, pretrained=True):\n        super(Resnet34, self).__init__()\n        if pretrained:\n            self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')\n        else:\n            self.model = pretrainedmodels.__dict_['resnet34'](pretrained=None)\n        \n        self.l0 = nn.Linear(512, 168)\n        self.l1 = nn.Linear(512, 11)\n        self.l2 = nn.Linear(512, 7)\n    \n    def forward(self, x):\n        bs, _, _, _  = x.shape\n        x = self.model.features(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n        l0 = self.l0(x)\n        l1 = self.l1(x)\n        l2 = self.l2(x)\n\n        return l0, l1, l2","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BengaliaiDataset:\n    def __init__(self, df, img_height, img_width, mean, std):\n        self.image_ids = df.image_id.values\n        self.img_arr = df.loc[:, 1:].values\n        self.aug = albumentations.Compose([\n            albumentations.Resize(img_height, img_width, always_apply=True),\n            albumentations.Normalize(mean, std, always_apply=True)\n        ])\n\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n\n    def __getitem__(self, item):\n        image = self.img_arr[item,:]\n        img_id = self.image_ids[item]\n        image = image.reshape(137, 236).astype(float)\n        image = Image.fromarray(image).convert(\"RGB\")\n\n        image = self.aug(image=np.array(image))[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            \"image\" : torch.tensor(image, dtype = torch.float),\n            \"img_id\" : img_id\n        }","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Resnet34(pretrained=False)\nmodel.load_state_dict(torch.load(\"../input/bengaliaimodels/resnet34_fold0.bin\"))\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor file_idx in range(4):\n    df = pd.read_csv(\"../input/bengaliai-cv19/test_image_data_{}.parquet\".format(file_idx))\n    test_ds = BengaliaiDataset(df = df, img_height=IMG_HEIGHT, img_width=IMG_WIDTH, mean = MODEL_MEAN, std = MODEL_STD)\n    test_loader = torch.utils.data.DataLoader(dataset=test_ds, batch_size=TEST_BATCH_SIZE, shuffle=False)\n    \n    \n    for bi, d in enumerate(test_ds);\n        image = d[\"image\"]\n        img_id = d[\"img_id\"]\n        image = image.to(DEVICE, dtype = torch.float)\n        g, v, c = model(image)\n        \n        g = np.argmax(g, axis=1)\n        v = np.argmax(v, axis=1)\n        c = np.argmax(c, axis=1)\n        \n        for ii, iimd in enumerate(img_id);\n            predictions.append((iimd, g[ii], v[ii], c[ii]))\n            \n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}